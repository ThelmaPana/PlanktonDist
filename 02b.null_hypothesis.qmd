---
title: "Generate random data for null hypothesis"
author: "Thelma Panaïotis"
format: 
  html:
    toc: true
    embed-resources: true
editor: visual
lightbox: true
execute:
  warning: false
  cache: false
  freeze: false
---

```{r set_up}
#| echo: false
#| cache: false
source("utils.R")
```

::: callout-note
## Aims

1.  See how the distribution of distances between random points look like. This null data is not used for comparison with true distances, representative null datasets are generated on the fly when computing plankton distances.

2.  Check that two null datasets with the same number of images have the same distance distribution.

3.  Assess the effect of the number of distances (& number of images) on the Kuiper test statistic.
:::

```{r read}
#| cache.lazy: false

## Load data
images <- read_parquet("data/00.images_clean.parquet")
plankton <- read_parquet("data/01.x_corrected_plankton_clean.parquet")
load("data/01.corr_factor.Rdata")

# list img names
img_names <- sort(unique(images$img_name))

## Apply correction factor in x
vol$x <- vol$x * med_corr
```

## Distribution of distances between objects if they are randomly distributed.

First, we need to generate a null dataset that is representative of the true dataset in terms of number of objects per image.

### Number of objects per image

```{r count_obj}
# Number of objects per image
counts <- plankton %>% count(img_name)
ggplot(counts) + geom_histogram(aes(x = n), bins = 100)
```

Let’s generate `r n_img` images with a similar distribution of number of objects per image.

```{r n_pts}
n_pts <- counts %>% slice_sample(n = n_img, replace = TRUE) %>% pull(n)
```

### Distances between random objects

Generate our random data.

```{r pick_rand}
set.seed(seed)
# Pick random points within image volumes
rand_points <- mclapply(1:n_img, function(i){
  # Number of points to sample within image
  n <- n_pts[i]
  # Draw points
  d_points <- tibble(
    x = runif(n = n, min = 1, max = vol$x),
    y = runif(n = n, min = 1, max = vol$y),
    z = runif(n = n, min = 1, max = vol$z)
  ) %>% # Add information for img name
  mutate(img_name = paste0("img_", str_pad(i, nchar(n_img), pad = "0")))
}, mc.cores = n_cores) %>% 
  bind_rows()
```

Compute and plot distances between all objects within each image.

```{r rand_dist}
#| output: false 
# Loop over images and compute distances between all points within each image
dist_all_rand <- compute_all_dist(rand_points, n_cores = n_cores)

# Save it
save(dist_all_rand, rand_points, file = "data/02.null_data.Rdata")
```

```{r plot_rand_dist}
# Plot all
ggplot(dist_all_rand) + 
  geom_density(aes(x = dist)) +
  labs(title = "Density distribution of distances for a random distribution")
```

## Check that two independent sets of null data return the same results.

```{r two_sets}
#| output: false 
# Pick random points within image volumes
set.seed(seed + 1)
set_1 <- mclapply(1:n_img, function(i){
  # Number of points to sample within image
  n <- n_pts[i]
  # Draw points
  d_points <- tibble(
    x = runif(n = n, min = 1, max = vol$x),
    y = runif(n = n, min = 1, max = vol$y),
    z = runif(n = n, min = 1, max = vol$z)
  ) %>% # Add information for img name
  mutate(img_name = paste0("img_", str_pad(i, nchar(n_img), pad = "0")))
}, mc.cores = n_cores) %>% 
  bind_rows()

# Pick random points within image volumes
set.seed(seed + 2)
set_2 <- mclapply(1:n_img, function(i){
  # Number of points to sample within image
  n <- n_pts[i]
  # Draw points
  d_points <- tibble(
    x = runif(n = n, min = 1, max = vol$x),
    y = runif(n = n, min = 1, max = vol$y),
    z = runif(n = n, min = 1, max = vol$z)
  ) %>% # Add information for img name
  mutate(img_name = paste0("img_", str_pad(i, nchar(n_img), pad = "0")))
}, mc.cores = n_cores) %>% 
  bind_rows()


## Compute distances
dist_1 <- compute_all_dist(set_1, n_cores = n_cores)
dist_2 <- compute_all_dist(set_2, n_cores = n_cores)
```

```{r two_sets_plot}
sets <- bind_rows(
  dist_1 %>% mutate(set = "1"),
  dist_2 %>% mutate(set = "2")
) 

sets %>% 
  ggplot() +
  geom_density(aes(x = dist, colour = set)) +
  labs(title = "Density distribution of distances for two random distributions")
```

```{r two_set_comp}
# Extract 10000-quantiles to perform comparison
probs <- seq(0, 1, length.out = 10000)
dist_1 <- quantile(dist_1$dist, probs = probs, names = FALSE)
dist_2 <- quantile(dist_2$dist, probs = probs, names = FALSE)

tibble(dist = dist_1, set = "1") %>% 
  bind_rows(tibble(dist = dist_2, set = "2")) %>%   
  ggplot(aes(dist, colour = set)) +
  stat_ecdf(geom = "step")

kuiper_test(dist_1, dist_2)
```

## Effect of number of distances on Kuiper test statistic

To investigate the effect on the number of distances on the Kuiper statistic, we generate multiple null distributions and compute pair-wise Kuiper statistics for various number of distances. Ideally, we want as many null datasets as possible, but the maximal number of distances is limited by computation cost. A good compromise is to generate 50/100 of these datasets, with a maximum of 10⁷ distances (\~14,000 images). We can then use a quantile regression (0.05 and 0.95 quantiles) to estimate a range of Kuiper statistics for higher number of distances.

### Load and plot

Null dataset generation, distances computation and pair-wise Kuiper tests are done in `02a.null_datasets.R`. We just need to load the data and plot.

```{r load_plot}
load("data/02a.f_val_dist.Rdata")

ggplot(f_val_dist) +
  geom_boxplot(aes(x = n_dist, y = test_stat, group = n_dist), colour = "gray") +
  scale_x_log10() + scale_y_log10() +
  labs(x = "N distances", y = "Kuiper statistic")
```

As expected, the Kuiper statistic decreases with the number of computed distances.

### Quantile regression

Let’s do a quantile regression to estimate Kuiper statistic for larger number of distances.

```{r quant_reg}
# Apply log-transformation
f_val_dist <- f_val_dist %>% 
  mutate(
    log_n_dist = log10(n_dist),
    log_test_stat = log10(test_stat)
  )

# Perform quantile regression on 0.05 and 0.95 quantiles
rqfit <- rq(log_test_stat ~ log_n_dist, data = f_val_dist, tau = c(0.05, 0.95))

#  Extract coefficients
rq_coef <- tidy(rqfit) %>% 
  select(term, estimate, tau) %>% 
  mutate(tau = as.factor(tau)) %>% 
  mutate(term = case_when(
    term == "(Intercept)" ~ "intercept",
    term == "log_n_dist" ~ "slope",
  )) %>% 
  pivot_wider(names_from = "term", values_from = estimate)

# Save quantile reg coefts
save(rq_coef, file = "data/02b.rq_coef.Rdata")

# Generate data to plot a ribbon between the regression lines
lim_dist <- c(5e1, 5e9) # extend of the ribbon in x-axis
rib_data <- tibble(n_dist = lim_dist) %>% 
  mutate(
    # apply log-transformation
    log_n_dist = log10(n_dist),
    # compute estimated kuiper-stat from slope and intercept
    ymin = rq_coef %>% filter(tau == 0.05) %>% pull(slope) * log_n_dist + rq_coef %>% filter(tau == 0.05) %>% pull(intercept),
    ymax = rq_coef %>% filter(tau == 0.95) %>% pull(slope) * log_n_dist + rq_coef %>% filter(tau == 0.95) %>% pull(intercept)
  ) %>% 
  # reformat and reorder to plot a polygon
  pivot_longer(ymin:ymax, values_to = "y") %>% 
  mutate(order = c(1, 2, 4, 3)) %>% 
  arrange(order)


# Plot
ggplot(f_val_dist) +
  geom_boxplot(aes(x = log_n_dist, y = log_test_stat, group = log_n_dist), colour = "gray") +
  geom_polygon(data = rib_data, aes(x = log_n_dist, y = y), alpha = 0.1) +
  geom_abline(data = rq_coef, aes(slope = slope, intercept = intercept, group = tau), linetype = 2) +
  scale_x_continuous(labels = label_math(expr = 10^.x, format = force), expand = c(0, 0)) +
  scale_y_continuous(labels = label_math(expr = 10^.x, format = force)) +
  labs(x = "N distances", y = "Kuiper statistic")
```
