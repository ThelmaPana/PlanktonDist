---
title: "Correct distances in x axis"
subtitle: "Extract solitary Collodaria, prepare Ecotaxa import, get data from Ecotaxa."
author: "Thelma Pana√Øotis"
format: 
  html:
    toc: true
    embed-resources: true
editor: visual
lightbox: true
execute:
  warning: false
  cache: true
  freeze: false
---

```{r r_set_up}
#| echo: false
#| cache: false
source("utils.R")
load("data/01.null_data.Rdata")
```

```{python py_set_up}
#| echo: false
#| cache: false
#| eval: false

import pandas as pd
import numpy as np
import os
import tarfile
import cv2
import matplotlib.pyplot as plt

# Path to apeep processed data
apeep_path = '/home/tpanaiotis/complex/visufront/apeep_processed'

# Path to write images
vig_path = 'data/solitary_collodaria/images'
```

## Extract solitary collodaria and prepare Ecotaxa import

### Get objects of interest

```{r read}
#| cache.lazy: false

## All data, because not so many solitary collodaria
images <- read_parquet("data/00.images_clean.parquet")
plankton <- read_parquet("data/00.plankton_clean.parquet")

# Get solitary Collodaria
plankton <- plankton %>% filter(taxon == "Collodaria_solitaryblack")

# List img names
images <- images %>% filter(img_name %in% plankton$img_name)
img_names <- sort(unique(images$img_name))

```

### Prepare table for Ecotaxa

First, we need to prepare some new columns.

```{r new_cols}
plankton_eco <- plankton %>% 
  mutate(
    # Date and time as YYYYMMDD and HHMMSS
    date = datetime %>% as_date() %>% as.character() %>% str_replace_all("-", ""),
    time = datetime %>% as_hms() %>% as.character() %>% str_replace_all(":", ""),
    depth_max = depth, # for depth_max
    # path to vignette
    img_file_name = paste("images", img_name, paste0(object_id, ".png"), sep = "/"),
    transect = str_remove_all(transect, "0") # remove "0" in transect name
  ) %>% 
  select(
    # select relevant columns and rename
    object_id,
    img_file_name,
    sample_id = transect,
    process_id = img_name,
    object_lon = lon,
    object_lat = lat,
    object_date = date,
    object_time = time,
    object_depth_min = depth,
    object_depth_max = depth_max,
    object_dist = dist,
    object_x = x,
    object_y = y,
    object_height = height,
    object_width = width
  )
```

Now move to python to add header row and save as tsv.

```{python first_row}
run = False
if run:
  df = r.plankton_eco
  
  # add first row, containing data format codes; [f] for floats, [t] for text
  # initiate first_row as floats
  first_row = ['[f]'] * (df.shape[1])
  
  # list of possible columns with data format as text [t]
  as_text = [
      'img_file_name',
      'object_id',
      'sample_id',
      'process_id'
  ]
  
  # for columns in particles_props and with text format, change first row to [t]
  col_ind_text = [df.columns.get_loc(col) for col in list(set(df_ecotaxa.columns) & set(as_text  ))]
  for i in col_ind_text:
      first_row[i] = '[t]'
      
  # first_row as Dataframe row with appropriate headers
  first_row = pd.DataFrame(first_row).T
  first_row.columns = df.columns
  
  # concat first_row and dataframe
  df_ecotaxa = pd.concat([first_row, df], ignore_index = True)
  
  ## Save as tsv file
  df_ecotaxa.to_csv('data/solitary_collodaria/ecotaxa_solitary_collodaria.tsv', index = False,   sep = '\t', header = True)
```

Now that the table is ready, we have to prepare images.

### Prepare images

::: {.callout-note icon="false"}
This part is to be run at LOV only (because images are at LOV).
:::

```{python move_images}
run = False
if run:
  df['img_path'] = df['sample_id'] + '/particles/' + df['process_id']
  df = df.sort_values(by = 'img_path').reset_index(drop = True)
  
  # put this in a list
  img_path = df['img_path'].tolist()
  # drop duplicates
  img_path = list(set(img_path))
  img_path.sort()
  
  for i, p in enumerate(img_path):
      # progress flag
      if i + 1 % 1000 == 0:
          print(f'Done with {i+1} out of {len(img_path)}')
          
      # get concerned vignettes
      vig_name = df[df['img_path'] == p].object_id.tolist()
      vig_name = [v + '.png' for v in vig_name]
      
      # Open tar file
      tar = tarfile.open(name = os.path.join(apeep_path, p + '.tar'), mode='r')
      # Get names of all vignettes
      all_vigs = tar.getnames()
      all_vigs = [x for x in all_vigs if 'png' in x]
      
      # Get names of vignettes to extract
      vig_name = [p for p in all_vigs if os.path.basename(p) in vig_name]
      
      # Loop over vignettes to process
      for v in vig_name:
      
          # Read vignette as image
          vignette = tar.extractfile(v)
          vignette = vignette.read()
          vignette = cv2.imdecode(
              np.asarray(
                  bytearray(
                      vignette
                  ), dtype=np.uint8
              ), 0
          )/255
          
          # Save image as png
          os.makedirs(os.path.join(vig_path, os.path.basename(p)), exist_ok = True)
          _ = cv2.imwrite(
              filename = os.path.join(vig_path, os.path.basename(p), os.path.basename(v)), 
              img = (vignette * 255).astype(np.uint8)
          )
```

## Read from Ecotaxa

```{r read_eco}
# Fields to extract
fields <- "obj.orig_id,sam.orig_id,txo.display_name,obj.classif_qual"

# Extract object from project
o <- get_object_set(project_id = 11779, ProjectFilters = ProjectFilters(), fields = fields)

# Get details
sol_col <- o$details %>% 
  as_tibble(.name_repair = "minimal") %>% 
  setNames(str_split(fields, ",")[[1]]) %>% 
  # rename columns
  rename(
    object_id = obj.orig_id,
    transect_new = sam.orig_id, # missed "0" in front of transect number, keep it for sanity check
    group = txo.display_name,
    classif_qual = obj.classif_qual
  ) %>% 
  # keep only validated objects
  filter(classif_qual == "V")

# Join with plankton table
sol_col <- sol_col %>% 
  left_join(plankton, by = join_by(object_id)) %>% 
  filter(transect_new == str_remove_all(transect, "0")) %>%  # make sure that transects are ok
  select(transect, img_name:taxon, group) %>% 
  mutate(ratio = height/width)
```

```{r}
sol_col %>% 
  ggplot() +
  geom_point(aes(x = width, y = height, colour = group)) +
  geom_abline(slope = 1, intercept = 0)
```

```{r}
#| fig-column: screen-inset
#| out-width: 100%
#| fig-width: 10
#| fig-height: 7
sol_col %>% 
  filter(group == "solitaryblack") %>% 
  group_by(transect, img_name, datetime, lat, lon, dist, depth) %>% 
  summarise(ratio = mean(ratio)) %>% 
  ungroup() %>% 
  ggplot() +
  geom_point(aes(x = dist,  y = -depth, colour = ratio)) +
  scale_colour_viridis_c() +
  facet_wrap(~transect, scales = "free")
```

```{r}
sol_col %>% 
  filter(group == "solitaryblack") %>% 
  ggplot() +
  geom_boxplot(aes(x = 0, y = ratio)) +
  facet_wrap(~transect, nrow = 2)
```

```{r}
#| fig-column: screen-inset
#| out-width: 100%
#| fig-width: 10
#| fig-height: 5
sol_col %>% 
  filter(group == "solitaryblack") %>% 
  group_by(transect, img_name, datetime, lat, lon, dist, depth) %>% 
  summarise(ratio = mean(ratio)) %>% 
  ungroup() %>% 
  arrange(datetime) %>% 
  ggplot() +
  geom_path(aes(x = datetime, y = ratio)) +
  facet_wrap(~transect, scales = "free_x", nrow = 4)
```

## Apply to null data

Compare error in `z` to error in `x`.

```{r}


toto <- rand_points %>% filter(img_name == "img_00001")

corr_factor <- mean(sol_col$ratio) # just start with the mean


x <- toto$x
y <- sol_col$ratio
apply_corr <- function(x, y){
  y_sum <- summary(y)
  res <- x %*% t(unname(y_sum)) %>% 
    as.data.frame() %>% 
    set_names(c("min", "q1", "med", "mean", "q3", "max"))
  
  
  return(res)
}

as.data.frame(res) %>% 
  set_names(c("min", "q1", "med", "mean", "q3", "max"))



titi <- toto %>% 
  mutate(cors = apply_corr(x, sol_col$ratio)) %>% 
  unnest_wider(cors)


toto$x
foo <- apply_corr(toto$x, sol_col$ratio)

# Apply correction
titi <- toto %>% mutate(x = x * corr_factor)

toto %>% 
  left_join(titi %>% rename(x_corr = x), by = join_by(y, z, img_name)) %>% 
  pivot_longer(c(x,x_corr)) %>% 
  ggplot() +
  geom_point(aes(x = value, y = y, color = name)) +
  coord_fixed()


dist_all <- compute_all_dist(toto)
dist_all_corr <- compute_all_dist(titi)

dist_all %>% 
  left_join(dist_all_corr %>% rename(dist_corr = dist), by = join_by(p1, p2, img_name)) %>% 
  ggplot() + 
  geom_point(aes(x = dist, y = dist_corr)) + 
  geom_abline(slope = 1, intercept = 0, colour = "red")
```
